{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Import Data, Create Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/philb/Google Drive/Thinkful/Thinkful_repo/projects/supervised_capstone/target_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7276, 136)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "target = df.iloc[:, 0]\n",
    "features = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7276,)\n",
      "(7276, 135)\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Create a holdout group of 20% that we can test our best models on at the end (in order to verify that our model was generalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X, X_holdout, y, y_holdout = train_test_split(features, target, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Create a small validation set (mini holdout) to predict after cross validation to try and find best generalization before testing on holdout. Ultimately, the chosen model will train on this validation set as well (and be adopted, if it has better cross validation score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Classification Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**The Models:**\n",
    "1. Naive Bayes: Multinomial, Bernoulli\n",
    "2. Logistic Regression\n",
    "3. K-Nearest Neighbors Classifier\n",
    "4. Decision Tree Classifier\n",
    "5. Random Forest Classifier\n",
    "6. Support Vector Machines (SVM) Classifier\n",
    "7. Gradient Boosting Classifier\n",
    "8. XGBoost or Extreme Gradient Boosting\n",
    "9. Extra-trees Classifier\n",
    "10. Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ol_scaler = RobustScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "scalers = [outlier_scaler, minmax_scaler, standard_scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "outlier_X_train = outlier_scaler.fit_transform(X_train) #outlier elimination using RobustScaler\n",
    "minmax_X_train = minmax_scaler.fit_transform(X_train) #MinMax scale between 0 and 1 (positives only)\n",
    "standard_X_train = standard_scaler.fit_transform(X_train) #StandardScaler with mean 0 and scaled std\n",
    "minmax_outlier_X_train = minmax_scaler.fit_transform(ol_X_train) #outlier removed and MinMaxed (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_datas = {'original': X_train,'outlier_removed':outlier_X_train, 'minmaxed':minmax_X_train, 'standardized':standard_X_train, 'minmaxed_outlier_removed':minmax_outlier_X_train}\n",
    "pca_obj = {}\n",
    "pca_data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for item in train_datas.items():\n",
    "    pca_obj[str(item[0])] = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for item in pca_obj.items():\n",
    "    pca_obj[item[0]].fit_transform(train_datas[item[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n",
      "[0.97850731 0.99464223 0.99912321 0.99945541 0.99970482 0.99974912\n",
      " 0.99978137 0.99980815 0.99983215 0.99985508 0.99987467 0.99988524\n",
      " 0.99989462 0.9999033  0.99991169 0.99991963 0.99992599 0.99993199\n",
      " 0.9999363  0.99994016 0.99994397 0.99994734 0.99995052 0.99995334\n",
      " 0.99995611 0.99995881 0.99996124 0.99996338 0.99996541 0.99996734\n",
      " 0.99996918 0.99997099 0.99997268 0.99997434 0.99997596 0.99997755\n",
      " 0.99997911 0.99998051 0.99998173 0.99998291 0.99998403 0.9999851\n",
      " 0.99998608 0.99998702 0.99998794 0.99998879 0.99998954 0.99999027\n",
      " 0.99999096 0.99999163 0.99999228 0.99999284 0.99999335 0.99999382\n",
      " 0.99999428 0.99999472 0.9999951  0.99999547 0.99999582 0.99999614\n",
      " 0.99999644 0.99999672 0.99999697 0.99999721 0.99999744 0.99999766\n",
      " 0.99999788 0.99999809 0.9999983  0.99999849 0.99999868 0.9999988\n",
      " 0.99999888 0.99999897 0.99999905 0.99999912 0.9999992  0.99999927\n",
      " 0.99999932 0.99999938 0.99999944 0.99999949 0.99999954 0.99999958\n",
      " 0.99999962 0.99999966 0.99999968 0.99999971 0.99999974 0.99999977\n",
      " 0.99999979 0.99999981 0.99999983 0.99999985 0.99999987 0.99999989\n",
      " 0.99999991 0.99999992 0.99999994 0.99999995 0.99999996 0.99999997\n",
      " 0.99999997 0.99999998 0.99999998 0.99999998 0.99999999 0.99999999\n",
      " 0.99999999 0.99999999 0.99999999 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "outlier_removed\n",
      "[0.25153687 0.4228111  0.5702114  0.60338065 0.63370466 0.65832041\n",
      " 0.67962799 0.69897981 0.71523278 0.73106152 0.74548515 0.75943903\n",
      " 0.77314533 0.78395299 0.79375303 0.80307296 0.81183741 0.81997729\n",
      " 0.82748043 0.83488015 0.84169995 0.84833424 0.85482269 0.86091466\n",
      " 0.86670122 0.87201694 0.8773016  0.88220234 0.88697244 0.89166424\n",
      " 0.89609728 0.9005024  0.90473639 0.90890062 0.91295417 0.91689075\n",
      " 0.92074891 0.92448604 0.92799635 0.93132733 0.9345536  0.93771643\n",
      " 0.94077369 0.94373966 0.94659022 0.94932511 0.95197385 0.95444191\n",
      " 0.95688527 0.95930692 0.96157412 0.96370913 0.96576582 0.9676081\n",
      " 0.96938961 0.97090782 0.97231917 0.9737012  0.97492157 0.97610095\n",
      " 0.97721577 0.97830261 0.97936164 0.98039083 0.98139217 0.98237608\n",
      " 0.98333089 0.9842213  0.98509001 0.98594237 0.98678928 0.98757123\n",
      " 0.98830106 0.98897776 0.98962527 0.99025376 0.99084961 0.99143227\n",
      " 0.99200586 0.9925529  0.99305796 0.99355523 0.99401508 0.99447227\n",
      " 0.99490201 0.99531641 0.99568966 0.99605623 0.99640382 0.99673236\n",
      " 0.99703954 0.99732573 0.99755121 0.99776882 0.99797331 0.99815103\n",
      " 0.99832132 0.99847123 0.99861897 0.99876064 0.99889686 0.99902521\n",
      " 0.99914135 0.99924957 0.99933349 0.99940673 0.99947597 0.99953731\n",
      " 0.99959698 0.99965316 0.99970546 0.99975608 0.99980243 0.99984638\n",
      " 0.99987039 0.99989297 0.99991401 0.99993101 0.99994571 0.9999562\n",
      " 0.99996607 0.99997511 0.99998128 0.99998708 0.99999149 0.99999447\n",
      " 0.99999633 0.99999773 0.99999898 0.99999965 0.99999987 1.\n",
      " 1.         1.         1.        ]\n",
      "minmaxed\n",
      "[0.13289783 0.24446881 0.33989265 0.42693581 0.49679683 0.54598132\n",
      " 0.57960306 0.6060781  0.63002239 0.64927361 0.66808885 0.68493999\n",
      " 0.70104639 0.71609    0.72991831 0.74199435 0.75296446 0.76339143\n",
      " 0.77264102 0.78147886 0.78971939 0.79785457 0.80575484 0.81333474\n",
      " 0.82045701 0.82721072 0.83383787 0.84022907 0.8463101  0.85231947\n",
      " 0.85819355 0.86402709 0.86931551 0.8744955  0.87963335 0.88471753\n",
      " 0.88969521 0.89441324 0.89899228 0.90349129 0.90763887 0.91177587\n",
      " 0.9157475  0.919567   0.92325661 0.92678801 0.93012035 0.93341128\n",
      " 0.93667476 0.93976742 0.94266907 0.94540506 0.94803169 0.95051734\n",
      " 0.95288671 0.95523126 0.95750784 0.95946932 0.96134969 0.96315108\n",
      " 0.96487221 0.96651463 0.96807335 0.96961398 0.97112308 0.972577\n",
      " 0.97400106 0.97536517 0.97671644 0.97798651 0.97921015 0.98034982\n",
      " 0.98147373 0.98246993 0.98343518 0.98432653 0.98516902 0.98600171\n",
      " 0.98678283 0.98753595 0.98825536 0.98894857 0.98962465 0.990285\n",
      " 0.99090594 0.99152212 0.99210096 0.99264627 0.99317035 0.99364453\n",
      " 0.99409796 0.99450067 0.99489457 0.99527403 0.99561186 0.99593385\n",
      " 0.9962316  0.9965155  0.99679338 0.99706215 0.99732293 0.99757697\n",
      " 0.99781766 0.99803506 0.99824283 0.99844242 0.9986151  0.99878484\n",
      " 0.9989157  0.99902489 0.9991309  0.99922713 0.99931627 0.99940186\n",
      " 0.9994842  0.99956577 0.99964512 0.99971916 0.9997849  0.99984327\n",
      " 0.99989245 0.99992484 0.99994545 0.99996205 0.99997461 0.99998326\n",
      " 0.99999079 0.99999554 0.99999793 0.99999942 0.99999978 1.\n",
      " 1.         1.         1.        ]\n",
      "standardized\n",
      "[0.08188589 0.14516423 0.1866334  0.22555112 0.26261728 0.29503763\n",
      " 0.32144976 0.34661788 0.36890515 0.39049169 0.40847981 0.42490105\n",
      " 0.44097725 0.45672291 0.47180791 0.4863825  0.50061462 0.51419218\n",
      " 0.527272   0.54009664 0.55272836 0.56483747 0.57677389 0.58846767\n",
      " 0.59992843 0.61091117 0.62174169 0.63243884 0.64292194 0.65318374\n",
      " 0.66321274 0.67308744 0.68270605 0.69206826 0.70121304 0.71004669\n",
      " 0.71876557 0.72727772 0.73573547 0.74406375 0.75235251 0.76052939\n",
      " 0.76832514 0.7760557  0.78365161 0.7911456  0.79861742 0.80583543\n",
      " 0.81299562 0.82011859 0.82718355 0.8341826  0.8410463  0.84784482\n",
      " 0.85425683 0.860542   0.86678386 0.87283746 0.87880808 0.88462652\n",
      " 0.8902656  0.89580553 0.90120546 0.90638706 0.91118433 0.91571924\n",
      " 0.92014684 0.92451378 0.92854672 0.93239314 0.93593224 0.93917943\n",
      " 0.94238245 0.94546985 0.94850116 0.95143335 0.95415904 0.95685291\n",
      " 0.9593925  0.96183814 0.96418629 0.96648998 0.96871203 0.9708163\n",
      " 0.97284229 0.97471004 0.97637617 0.97801888 0.97965112 0.98122701\n",
      " 0.98273081 0.98421412 0.98564671 0.986966   0.98813312 0.98927453\n",
      " 0.99037228 0.99137621 0.99233634 0.99310198 0.99378522 0.99440474\n",
      " 0.9949937  0.99552313 0.99600017 0.99645472 0.99689522 0.99729136\n",
      " 0.99767852 0.99806018 0.99841927 0.99874171 0.99890515 0.99906435\n",
      " 0.99921725 0.99935818 0.99949494 0.99961878 0.99973893 0.9998057\n",
      " 0.99985036 0.99988562 0.99991408 0.99994035 0.9999579  0.99997339\n",
      " 0.9999855  0.99999364 0.99999716 0.99999904 0.99999965 1.\n",
      " 1.         1.         1.        ]\n",
      "minmaxed_outlier_removed\n",
      "[0.13289783 0.24446881 0.33989265 0.42693581 0.49679683 0.54598132\n",
      " 0.57960306 0.6060781  0.63002239 0.64927361 0.66808885 0.68493999\n",
      " 0.70104639 0.71609    0.72991831 0.74199435 0.75296446 0.76339143\n",
      " 0.77264102 0.78147886 0.78971939 0.79785457 0.80575484 0.81333474\n",
      " 0.82045701 0.82721072 0.83383787 0.84022907 0.8463101  0.85231947\n",
      " 0.85819355 0.86402709 0.86931551 0.8744955  0.87963335 0.88471753\n",
      " 0.88969521 0.89441324 0.89899228 0.90349129 0.90763887 0.91177587\n",
      " 0.9157475  0.919567   0.92325661 0.92678801 0.93012035 0.93341128\n",
      " 0.93667476 0.93976742 0.94266907 0.94540506 0.94803169 0.95051734\n",
      " 0.95288671 0.95523126 0.95750784 0.95946932 0.96134969 0.96315108\n",
      " 0.96487221 0.96651463 0.96807335 0.96961398 0.97112308 0.972577\n",
      " 0.97400106 0.97536517 0.97671644 0.97798651 0.97921015 0.98034982\n",
      " 0.98147373 0.98246993 0.98343518 0.98432653 0.98516902 0.98600171\n",
      " 0.98678283 0.98753595 0.98825536 0.98894857 0.98962465 0.990285\n",
      " 0.99090594 0.99152212 0.99210096 0.99264627 0.99317035 0.99364453\n",
      " 0.99409796 0.99450067 0.99489457 0.99527403 0.99561186 0.99593385\n",
      " 0.9962316  0.9965155  0.99679338 0.99706215 0.99732293 0.99757697\n",
      " 0.99781766 0.99803506 0.99824283 0.99844242 0.9986151  0.99878484\n",
      " 0.9989157  0.99902489 0.9991309  0.99922713 0.99931627 0.99940186\n",
      " 0.9994842  0.99956577 0.99964512 0.99971916 0.9997849  0.99984327\n",
      " 0.99989245 0.99992484 0.99994545 0.99996205 0.99997461 0.99998326\n",
      " 0.99999079 0.99999554 0.99999793 0.99999942 0.99999978 1.\n",
      " 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "for pca_obj in pca_obj.items():\n",
    "    print(pca_obj[0])\n",
    "    print(pca_obj[1].explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def train_data_testing(classifier, verbose=0):\n",
    "    datas = []\n",
    "    means = []\n",
    "    \n",
    "    if verbose == False:\n",
    "        for x in train_datas:\n",
    "            try:\n",
    "                cvs = cross_val_score(classifier, train_datas[x], y_train, cv=5, n_jobs=-1)\n",
    "                cv_mean = cvs.mean()\n",
    "                datas.append(x)\n",
    "                means.append(cv_mean)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    elif verbose == True:\n",
    "        for x in train_datas:\n",
    "            try:\n",
    "                cvs = cross_val_score(classifier, train_datas[x], y_train, cv=5, n_jobs=-1)\n",
    "                cv_mean = cvs.mean()\n",
    "                print(f'Classifier: {classifier}')\n",
    "                print(f\"Train Data: {x}\")\n",
    "                print(f'CVs: {cvs}')\n",
    "                print(f'CVs Average: {cv_mean}')\n",
    "                print('-----')\n",
    "                datas.append(x)\n",
    "                means.append(cv_mean)\n",
    "\n",
    "            except:\n",
    "                print(f'Something went wrong using \"{x}\" data in conjuncion with {classifier}')\n",
    "                print('-----')\n",
    "\n",
    "    best_cv_average = max(np.array(means))\n",
    "    best_indicies = [i for i, x in enumerate(means) if x == best_cv_average]\n",
    "    best_datas = [datas[i] for i in best_indicies]\n",
    "    \n",
    "    return classifier, best_cv_average, best_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def classifier_testing(clfs_list, verbose=1):\n",
    "    classifiers = []\n",
    "    classifier_best_cv_averages = []\n",
    "    classifier_best_datas = []\n",
    "    \n",
    "    if verbose == 0:\n",
    "        for classifier in clfs_list:\n",
    "            classifier, best_cv_average, best_datas = train_data_testing(classifier)\n",
    "            classifiers.append(classifier)\n",
    "            classifier_best_cv_averages.append(best_cv_average)\n",
    "            classifier_best_datas.append(best_datas)\n",
    "\n",
    "        best_average = max(np.array(classifier_best_cv_averages))\n",
    "        best_idxs = [i for i, x in enumerate(classifier_best_cv_averages) if x == best_average]\n",
    "        best_classifiers = [classifiers[i] for i in best_idxs]\n",
    "        best_datas_for_best_classifiers = [classifier_best_datas[i] for i in best_idxs]\n",
    "    \n",
    "    elif verbose == 1:\n",
    "        for classifier in clfs_list:\n",
    "            print('Testing: {}'.format(classifier))\n",
    "            print('-----')\n",
    "            classifier, best_cv_average, best_datas = train_data_testing(classifier, verbose=0)\n",
    "            print('Finished: {}'.format(classifier))\n",
    "            print('Best CV Score: {}'.format(best_cv_average))\n",
    "            print('Best Data Transformation(s): {}'.format(best_datas))\n",
    "            print('-----')\n",
    "            classifiers.append(classifier)\n",
    "            classifier_best_cv_averages.append(best_cv_average)\n",
    "            classifier_best_datas.append(best_datas)\n",
    "\n",
    "        best_average = max(np.array(classifier_best_cv_averages))\n",
    "        best_idxs = [i for i, x in enumerate(classifier_best_cv_averages) if x == best_average]\n",
    "        best_classifiers = [classifiers[i] for i in best_idxs]\n",
    "        best_datas_for_best_classifiers = [classifier_best_datas[i] for i in best_idxs]\n",
    "\n",
    "        print('Best Classifier(s):')\n",
    "        print('-------------------')\n",
    "        for a, b in zip(best_classifiers, best_datas_for_best_classifiers):\n",
    "            print('Classifier: {}'.format(a))\n",
    "            print('Best Data Transformations for Classifier:')\n",
    "            for i, data in enumerate(b, 1):\n",
    "                print('{}. {}: {}% accuracy'.format(i, data, round(best_average*100, 5)))\n",
    "    \n",
    "    elif verbose == 2:\n",
    "        for classifier in clfs_list:\n",
    "            print('Testing: {}'.format(classifier))\n",
    "            print('-----')\n",
    "            classifier, best_cv_average, best_datas = train_data_testing(classifier, verbose=1)\n",
    "            print('Finished: {}'.format(classifier))\n",
    "            print('Best CV Score: {}'.format(best_cv_average))\n",
    "            print('Best Data Transformation(s): {}'.format(best_datas))\n",
    "            print('-----')\n",
    "            classifiers.append(classifier)\n",
    "            classifier_best_cv_averages.append(best_cv_average)\n",
    "            classifier_best_datas.append(best_datas)\n",
    "\n",
    "        best_average = max(np.array(classifier_best_cv_averages))\n",
    "        best_idxs = [i for i, x in enumerate(classifier_best_cv_averages) if x == best_average]\n",
    "        best_classifiers = [classifiers[i] for i in best_idxs]\n",
    "        best_datas_for_best_classifiers = [classifier_best_datas[i] for i in best_idxs]\n",
    "\n",
    "        print('Best Classifier(s):')\n",
    "        print('-------------------')\n",
    "        for a, b in zip(best_classifiers, best_datas_for_best_classifiers):\n",
    "            print('Classifier: {}'.format(a))\n",
    "            print('Best Data Transformations for Classifier:')\n",
    "            for i, data in enumerate(b, 1):\n",
    "                print('{}. {}: {}% accuracy'.format(i, data, round(best_average*100, 5)))\n",
    "                \n",
    "    return best_classifiers, best_average, best_datas_for_best_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "clf_list = [MultinomialNB(), BernoulliNB(), LogisticRegression(), KNeighborsClassifier(), DecisionTreeClassifier(), RandomForestClassifier(), \n",
    "            GradientBoostingClassifier(), ExtraTreesClassifier(), SVC(), XGBClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "-----\n",
      "Finished: MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Best CV Score: 0.7562042039414685\n",
      "Best Data Transformation(s): ['minmaxed', 'minmaxed_outlier_removed']\n",
      "-----\n",
      "Testing: BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "-----\n",
      "Finished: BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "Best CV Score: 0.7596382248080666\n",
      "Best Data Transformation(s): ['original']\n",
      "-----\n",
      "Testing: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "-----\n",
      "Finished: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Best CV Score: 0.8963333989515665\n",
      "Best Data Transformation(s): ['outlier_removed']\n",
      "-----\n",
      "Testing: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "-----\n",
      "Finished: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "Best CV Score: 0.7365411535685382\n",
      "Best Data Transformation(s): ['minmaxed', 'minmaxed_outlier_removed']\n",
      "-----\n",
      "Testing: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "-----\n",
      "Finished: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "Best CV Score: 0.8600621915031679\n",
      "Best Data Transformation(s): ['minmaxed']\n",
      "-----\n",
      "Testing: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "-----\n",
      "Finished: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Best CV Score: 0.8243591285898642\n",
      "Best Data Transformation(s): ['standardized']\n",
      "-----\n",
      "Testing: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "-----\n",
      "Finished: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Best CV Score: 0.9356640565191714\n",
      "Best Data Transformation(s): ['original']\n",
      "-----\n",
      "Testing: ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "-----\n",
      "Finished: ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Best CV Score: 0.8094690755849137\n",
      "Best Data Transformation(s): ['outlier_removed']\n",
      "-----\n",
      "Testing: SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "-----\n",
      "Finished: SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Best CV Score: 0.882779588354951\n",
      "Best Data Transformation(s): ['standardized']\n",
      "-----\n",
      "Testing: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "-----\n",
      "Finished: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Best CV Score: 0.9337540191167786\n",
      "Best Data Transformation(s): ['outlier_removed', 'standardized']\n",
      "-----\n",
      "Best Classifier(s):\n",
      "-------------------\n",
      "Classifier: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Best Data Transformations for Classifier:\n",
      "1. original: 93.56641% accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                             learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                             n_iter_no_change=None, presort='auto',\n",
       "                             random_state=None, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False)],\n",
       " 0.9356640565191714,\n",
       " [['original']])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_testing(clf_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
