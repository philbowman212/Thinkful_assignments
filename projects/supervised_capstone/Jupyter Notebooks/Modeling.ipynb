{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>NBA SUPERVISED LEARNING CAPSTONE</h1>\n",
    "\n",
    "## Part 3: NBA Modeling\n",
    "1. [NBA Data Aggregation](https://github.com/philbowman212/Thinkful_repo/blob/master/projects/supervised_capstone/Jupyter%20Notebooks/Data_Aggregation.ipynb)\n",
    "2. [NBA Data Cleaning and Exploration](https://github.com/philbowman212/Thinkful_repo/blob/master/projects/supervised_capstone/Jupyter%20Notebooks/Data_Cleaning_Exploration.ipynb)\n",
    "3. [NBA Modeling](https://github.com/philbowman212/Thinkful_repo/blob/master/projects/supervised_capstone/Jupyter%20Notebooks/Modeling.ipynb)*\n",
    "4. [NBA Model Testing](https://github.com/philbowman212/Thinkful_repo/blob/master/projects/supervised_capstone/Jupyter%20Notebooks/Model_Testing.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Import Data (and minor feature selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset imported is the resulting feature and target set from the [data cleaning and exploration process](https://github.com/philbowman212/Thinkful_repo/blob/master/projects/supervised_capstone/Jupyter%20Notebooks/Data_Cleaning_Exploration.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the data will be imported and a number of features will be dropped (we didn't get them all in the last notebook). There are two reasons I will drop a feature in this section. One, if a feature shows a very low correlation with the target variable (Pearson correlation less than .05) the feature will be dropped. Two, if a feature is a derivation of another feature and has very high correlation with the other, then the feature with the lower correlation to the target will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/philb/Google Drive/Thinkful/Thinkful_repo/projects/supervised_capstone/target_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "low_corr = []\n",
    "for col in df.columns[1:]:\n",
    "    corr = abs(df.teamWin_A.corr(df[col]))\n",
    "    if corr < .05:\n",
    "        low_corr.append((col, corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=[i[0] for i in low_corr]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['stkTotAlt_A', 'stkTotAlt_B', 'spread_B', 'ptsAllow_A', 'ptsAllow_B', 'lastFive_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "target = df.iloc[:, 0]\n",
    "features = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X, X_holdout, y, y_holdout = train_test_split(features, target, test_size=.2, random_state=795)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=795)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sscaler = StandardScaler() #for models that use Gradient Descent/work best with scaled numbers\n",
    "mmscaler = MinMaxScaler() #for models that require positive only data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "s_train = pd.DataFrame(sscaler.fit_transform(X_train.iloc[:, 1:]), columns=X_train.columns[1:], index=X_train.index).join(X_train.iloc[:, 0]).copy()\n",
    "s_test = pd.DataFrame(sscaler.transform(X_test.iloc[:, 1:]), columns=X_test.columns[1:], index=X_test.index).join(X_test.iloc[:, 0]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mm_train = pd.DataFrame(mmscaler.fit_transform(X_train.iloc[:, 1:]), columns=X_train.columns[1:], index=X_train.index).join(X_train.iloc[:, 0]).copy()\n",
    "mm_test = pd.DataFrame(mmscaler.transform(X_test.iloc[:, 1:]), columns=X_test.columns[1:], index=X_test.index).join(X_test.iloc[:, 0]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_fit_est_test(grid, train, test):\n",
    "    start = time.time()\n",
    "    grid.fit(train, y_train)\n",
    "    stop = time.time()\n",
    "    grid_time = stop - start\n",
    "    test_score = grid.score(test, y_test)\n",
    "    best_est = grid.best_estimator_\n",
    "    \n",
    "    print(best_est)\n",
    "    print('Training: {}'.format(grid.best_score_))\n",
    "    print('Testing: {}'.format(test_score))\n",
    "    print('Grid Time: {}s'.format(grid_time))\n",
    "    return best_est, test_score, grid_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Try logistic regression for scaled and pca data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89980916, 0.89312977, 0.90362595, 0.90544413, 0.8930277 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(log_reg, s_train, y_train, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 33 candidates, totalling 165 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 165 out of 165 | elapsed:   41.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Training: 0.8990073419511946\n",
      "Testing: 0.915807560137457\n",
      "Grid Time: 41.663997411727905s\n"
     ]
    }
   ],
   "source": [
    "log_reg_l2 = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "l2_params = {'solver': ('newton-cg', 'sag', 'lbfgs'),\n",
    "             'C': np.arange(0, 5.1, .5)}\n",
    "grid_l2 = GridSearchCV(log_reg_l2, l2_params, n_jobs=-1, error_score=0, verbose=5)\n",
    "best_l2 = grid_fit_est_test(grid_l2, s_train, s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=-1)]: Done 110 out of 110 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Training: 0.8997705184569508\n",
      "Testing: 0.9175257731958762\n",
      "Grid Time: 86.63157033920288s\n"
     ]
    }
   ],
   "source": [
    "log_reg_l1 = LogisticRegression(penalty='l1', max_iter=1000)\n",
    "l1_params = {'solver': ('liblinear', 'saga'),\n",
    "             'C': np.arange(0, 5.1, .5)}\n",
    "grid_l1 = GridSearchCV(log_reg_l1, l1_params, n_jobs=-1, error_score=0, verbose=5)\n",
    "best_l1 = grid_fit_est_test(grid_l1, s_train, s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if best_l2[1] >= best_l1[1]:\n",
    "    best_log = best_l2\n",
    "else:\n",
    "    best_log = best_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                     random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                     warm_start=False), 0.9175257731958762, 86.63157033920288)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators.append(best_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 2. K-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Try MinMaxed data for K-Neighbors Classifier, it works best in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79675573, 0.74141221, 0.7519084 , 0.76981853, 0.75644699])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn_clf, mm_train, y_train, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "knn_params = {'n_neighbors': np.arange(1, 31, 1),\n",
    "              'p': np.arange(1, 5, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_knn = GridSearchCV(knn_clf, knn_params, n_jobs=-1, error_score=0, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 19.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=-1, n_neighbors=27, p=4,\n",
      "                     weights='uniform')\n",
      "Training: 0.80966009755244\n",
      "Testing: 0.7955326460481099\n",
      "Grid Time: 1174.263000011444s\n"
     ]
    }
   ],
   "source": [
    "best_knn = grid_fit_est_test(grid_knn, mm_train, mm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                     random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                     warm_start=False), 0.9175257731958762, 86.63157033920288),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=27, p=4,\n",
       "                       weights='uniform'),\n",
       "  0.7955326460481099,\n",
       "  1174.263000011444)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators.append(best_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 3. Naive Bayes Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "nbm_clf = MultinomialNB()\n",
    "nbb_clf = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75763359, 0.71374046, 0.73568702, 0.75262655, 0.71251194])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nbm_clf, mm_train, y_train, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Can use original data here, because Bernoulli Naive Bayes only considers whether a feature is true or not - and it's extremely fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77480916, 0.77767176, 0.76908397, 0.79178606, 0.75644699])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nbb_clf, X_train, y_train, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Tuning Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Only one to really tune here is alpha for both situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "nb_params = {'alpha': np.arange(0, 5, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_nbm = GridSearchCV(nbm_clf, nb_params, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  25 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.4s finished\n",
      "C:\\Users\\philb\\Miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=0, class_prior=None, fit_prior=True)\n",
      "Training: 0.7344399119257494\n",
      "Testing: 0.7164948453608248\n",
      "Grid Time: 0.5251133441925049s\n"
     ]
    }
   ],
   "source": [
    "best_nbm = grid_fit_est_test(grid_nbm, mm_train, mm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_nbb = GridSearchCV(nbb_clf, nb_params, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  25 | elapsed:    0.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=3, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "Training: 0.7741504261539696\n",
      "Testing: 0.761168384879725\n",
      "Grid Time: 0.688366174697876s\n"
     ]
    }
   ],
   "source": [
    "best_nbb = grid_fit_est_test(grid_nbb, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_nbb[1] >= best_nbm[1]:\n",
    "    best_nb = best_nbb\n",
    "else:\n",
    "    best_nb = best_nbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                     random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                     warm_start=False), 0.9175257731958762, 86.63157033920288),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=27, p=4,\n",
       "                       weights='uniform'),\n",
       "  0.7955326460481099,\n",
       "  1174.263000011444),\n",
       " (BernoulliNB(alpha=3, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "  0.761168384879725,\n",
       "  0.688366174697876)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators.append(best_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83492366, 0.83396947, 0.82729008, 0.84622732, 0.84909265])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dt_clf, X_train, y_train, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dt_params = {'max_depth': np.arange(1, 16, 1), \n",
    "             'criterion': ('gini', 'entropy')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_dt = GridSearchCV(dt_clf, dt_params, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   20.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "Training: 0.8896543741843288\n",
      "Testing: 0.8917525773195877\n",
      "Grid Time: 20.52696919441223s\n"
     ]
    }
   ],
   "source": [
    "best_dt = grid_fit_est_test(grid_dt, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                     random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                     warm_start=False), 0.9175257731958762, 86.63157033920288),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=27, p=4,\n",
       "                       weights='uniform'),\n",
       "  0.7955326460481099,\n",
       "  1174.263000011444),\n",
       " (BernoulliNB(alpha=3, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "  0.761168384879725,\n",
       "  0.688366174697876),\n",
       " (DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=None, splitter='best'),\n",
       "  0.8917525773195877,\n",
       "  20.52696919441223)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators.append(best_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86641221, 0.84637405, 0.84541985, 0.85577841, 0.84527221])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf_clf, X_train, y_train, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "rf_params = {'criterion': ('gini', 'entropy'),\n",
    "             'max_depth': np.arange(1, 16, 1),\n",
    "             'n_estimators': np.arange(10, 101, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_rf = GridSearchCV(rf_clf, rf_params, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=15, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=-1,\n",
      "                       oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False)\n",
      "Training: 0.8579611321332488\n",
      "Testing: 0.8608247422680413\n",
      "Grid Time: 1001.1802411079407s\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid_fit_est_test(grid_rf, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                     random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                     warm_start=False), 0.9175257731958762, 86.63157033920288),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=27, p=4,\n",
       "                       weights='uniform'),\n",
       "  0.7955326460481099,\n",
       "  1174.263000011444),\n",
       " (BernoulliNB(alpha=3, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "  0.761168384879725,\n",
       "  0.688366174697876),\n",
       " (DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=None, splitter='best'),\n",
       "  0.8917525773195877,\n",
       "  20.52696919441223),\n",
       " (RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='entropy', max_depth=15, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=-1,\n",
       "                         oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=False),\n",
       "  0.8608247422680413,\n",
       "  1001.1802411079407)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators.append(best_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 6. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sv_clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89885496, 0.8759542 , 0.88931298, 0.89684814, 0.87774594])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sv_clf, s_train, y_train, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sv_params = {'kernel': ('linear', 'rbf', 'sigmoid'),\n",
    "             'C': np.arange(.0001, 5.1, .1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_sv = GridSearchCV(sv_clf, sv_params, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 153 candidates, totalling 765 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed: 19.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.10010000000000001, break_ties=False, cache_size=200, class_weight=None,\n",
      "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Training: 0.8982443477183082\n",
      "Testing: 0.9140893470790378\n",
      "Grid Time: 1197.9056677818298s\n"
     ]
    }
   ],
   "source": [
    "best_sv = grid_fit_est_test(grid_sv, s_train, s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                     random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                     warm_start=False), 0.9175257731958762, 86.63157033920288),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=27, p=4,\n",
       "                       weights='uniform'),\n",
       "  0.7955326460481099,\n",
       "  1174.263000011444),\n",
       " (BernoulliNB(alpha=3, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "  0.761168384879725,\n",
       "  0.688366174697876),\n",
       " (DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=None, splitter='best'),\n",
       "  0.8917525773195877,\n",
       "  20.52696919441223),\n",
       " (RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='entropy', max_depth=15, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=-1,\n",
       "                         oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=False),\n",
       "  0.8608247422680413,\n",
       "  1001.1802411079407),\n",
       " (SVC(C=0.10010000000000001, break_ties=False, cache_size=200, class_weight=None,\n",
       "      coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale',\n",
       "      kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "      shrinking=True, tol=0.001, verbose=False),\n",
       "  0.9140893470790378,\n",
       "  1197.9056677818298)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators.append(best_sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91030534, 0.91221374, 0.89980916, 0.91212989, 0.89875836])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(gb_clf, s_train, y_train, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gb_params = {'loss': ('deviance', 'exponential'),\n",
    "             'n_estimators': np.arange(50, 501, 50),\n",
    "             'max_depth': np.arange(1, 6, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_gb = GridSearchCV(gb_clf, gb_params, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 49.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 76.6min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 96.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='exponential', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=350,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Training: 0.910653120146985\n",
      "Testing: 0.9175257731958762\n",
      "Grid Time: 5828.406820297241s\n"
     ]
    }
   ],
   "source": [
    "best_gb = grid_fit_est_test(grid_gb, s_train, s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                     random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                     warm_start=False), 0.9175257731958762, 86.63157033920288),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=27, p=4,\n",
       "                       weights='uniform'),\n",
       "  0.7955326460481099,\n",
       "  1174.263000011444),\n",
       " (BernoulliNB(alpha=3, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "  0.761168384879725,\n",
       "  0.688366174697876),\n",
       " (DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=None, splitter='best'),\n",
       "  0.8917525773195877,\n",
       "  20.52696919441223),\n",
       " (RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='entropy', max_depth=15, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=-1,\n",
       "                         oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=False),\n",
       "  0.8608247422680413,\n",
       "  1001.1802411079407),\n",
       " (SVC(C=0.10010000000000001, break_ties=False, cache_size=200, class_weight=None,\n",
       "      coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale',\n",
       "      kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "      shrinking=True, tol=0.001, verbose=False),\n",
       "  0.9140893470790378,\n",
       "  1197.9056677818298),\n",
       " (GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                             learning_rate=0.1, loss='exponential', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=350,\n",
       "                             n_iter_no_change=None, presort='deprecated',\n",
       "                             random_state=None, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False),\n",
       "  0.9175257731958762,\n",
       "  5828.406820297241)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators.append(best_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 8. eXtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91507634, 0.91316794, 0.90171756, 0.91404011, 0.90066858])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(xgb_clf, s_train, y_train, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "xgb_params = {'learning_rate': np.arange(.01, .21, .01)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_xgb = GridSearchCV(xgb_clf, xgb_params, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.15000000000000002, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Training: 0.9127530858796853\n",
      "Testing: 0.9192439862542955\n",
      "Grid Time: 92.24156093597412s\n"
     ]
    }
   ],
   "source": [
    "best_xgb = grid_fit_est_test(grid_xgb, s_train, s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                     random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                     warm_start=False), 0.9175257731958762, 86.63157033920288),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=27, p=4,\n",
       "                       weights='uniform'),\n",
       "  0.7955326460481099,\n",
       "  1174.263000011444),\n",
       " (BernoulliNB(alpha=3, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "  0.761168384879725,\n",
       "  0.688366174697876),\n",
       " (DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=None, splitter='best'),\n",
       "  0.8917525773195877,\n",
       "  20.52696919441223),\n",
       " (RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='entropy', max_depth=15, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=-1,\n",
       "                         oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=False),\n",
       "  0.8608247422680413,\n",
       "  1001.1802411079407),\n",
       " (SVC(C=0.10010000000000001, break_ties=False, cache_size=200, class_weight=None,\n",
       "      coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale',\n",
       "      kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "      shrinking=True, tol=0.001, verbose=False),\n",
       "  0.9140893470790378,\n",
       "  1197.9056677818298),\n",
       " (GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                             learning_rate=0.1, loss='exponential', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=350,\n",
       "                             n_iter_no_change=None, presort='deprecated',\n",
       "                             random_state=None, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False),\n",
       "  0.9175257731958762,\n",
       "  5828.406820297241),\n",
       " (XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "                learning_rate=0.15000000000000002, max_delta_step=0, max_depth=3,\n",
       "                min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "                nthread=None, objective='binary:logistic', random_state=0,\n",
       "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "                silent=None, subsample=1, verbosity=1),\n",
       "  0.9192439862542955,\n",
       "  92.24156093597412)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators.append(best_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Extremely Randomized Trees (Extra Trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_clf = ExtraTreesClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85209924, 0.82538168, 0.83587786, 0.84718243, 0.83667622])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(et_clf, s_train, y_train, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_params = {'n_estimators': np.arange(100, 501, 100),\n",
    "             'criterion': ('gini', 'entropy'),\n",
    "             'min_samples_split': np.arange(1, 6, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_et = GridSearchCV(et_clf, et_params, n_jobs=-1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=3,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Training: 0.8495599932923584\n",
      "Testing: 0.8436426116838488\n",
      "Grid Time: 401.22411918640137s\n"
     ]
    }
   ],
   "source": [
    "best_et = grid_fit_est_test(grid_et, s_train, s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                     random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                     warm_start=False), 0.9175257731958762, 86.63157033920288),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=27, p=4,\n",
       "                       weights='uniform'),\n",
       "  0.7955326460481099,\n",
       "  1174.263000011444),\n",
       " (BernoulliNB(alpha=3, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "  0.761168384879725,\n",
       "  0.688366174697876),\n",
       " (DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=None, splitter='best'),\n",
       "  0.8917525773195877,\n",
       "  20.52696919441223),\n",
       " (RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='entropy', max_depth=15, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=-1,\n",
       "                         oob_score=False, random_state=None, verbose=0,\n",
       "                         warm_start=False),\n",
       "  0.8608247422680413,\n",
       "  1001.1802411079407),\n",
       " (SVC(C=0.10010000000000001, break_ties=False, cache_size=200, class_weight=None,\n",
       "      coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale',\n",
       "      kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "      shrinking=True, tol=0.001, verbose=False),\n",
       "  0.9140893470790378,\n",
       "  1197.9056677818298),\n",
       " (GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                             learning_rate=0.1, loss='exponential', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=350,\n",
       "                             n_iter_no_change=None, presort='deprecated',\n",
       "                             random_state=None, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False),\n",
       "  0.9175257731958762,\n",
       "  5828.406820297241),\n",
       " (XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "                learning_rate=0.15000000000000002, max_delta_step=0, max_depth=3,\n",
       "                min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "                nthread=None, objective='binary:logistic', random_state=0,\n",
       "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "                silent=None, subsample=1, verbosity=1),\n",
       "  0.9192439862542955,\n",
       "  92.24156093597412),\n",
       " (ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False),\n",
       "  0.8436426116838488,\n",
       "  401.22411918640137)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators.append(best_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = total_stop - total_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = [grid_l1, grid_knn, grid_nbb, grid_dt, grid_rf, grid_sv, grid_gb, grid_xgb, grid_et]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_time = [i[2] for i in best_estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_candidates = [len(grid.cv_results_['params']) for grid in grids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_candidate = [a/b for a, b in zip(fit_time, no_candidates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_names = [str(i[0]).split('(')[0] for i in best_estimators]\n",
    "clf_data = [(round(a[1]*100, 3), round(b, 3)) for a, b in zip(best_estimators, time_per_candidate)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_stats = pd.DataFrame(clf_data, columns=['Testing Accuracy(%)', 'Candidate Fit Time (Seconds/Candidate)'], index=class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_stats.index.rename('Classifier', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testing Accuracy(%)</th>\n",
       "      <th>Candidate Fit Time (Seconds/Candidate)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>91.924</td>\n",
       "      <td>4.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>91.753</td>\n",
       "      <td>3.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>91.753</td>\n",
       "      <td>58.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>91.409</td>\n",
       "      <td>7.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>89.175</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>86.082</td>\n",
       "      <td>3.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>84.364</td>\n",
       "      <td>8.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>79.553</td>\n",
       "      <td>9.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>76.117</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Testing Accuracy(%)  \\\n",
       "Classifier                                        \n",
       "XGBClassifier                            91.924   \n",
       "LogisticRegression                       91.753   \n",
       "GradientBoostingClassifier               91.753   \n",
       "SVC                                      91.409   \n",
       "DecisionTreeClassifier                   89.175   \n",
       "RandomForestClassifier                   86.082   \n",
       "ExtraTreesClassifier                     84.364   \n",
       "KNeighborsClassifier                     79.553   \n",
       "BernoulliNB                              76.117   \n",
       "\n",
       "                            Candidate Fit Time (Seconds/Candidate)  \n",
       "Classifier                                                          \n",
       "XGBClassifier                                                4.612  \n",
       "LogisticRegression                                           3.938  \n",
       "GradientBoostingClassifier                                  58.284  \n",
       "SVC                                                          7.829  \n",
       "DecisionTreeClassifier                                       0.684  \n",
       "RandomForestClassifier                                       3.337  \n",
       "ExtraTreesClassifier                                         8.024  \n",
       "KNeighborsClassifier                                         9.786  \n",
       "BernoulliNB                                                  0.138  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_stats.sort_values('Testing Accuracy(%)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the testing and validation data the XGBClassifier, GradientBoostingClassifier, LogisticRegression and SVC models all had results greater than 91%.\n",
    "\n",
    "Take note of how long it took for the average candidate in the GradientBoosting GridSearch to complete, for a possible deployment, this is likely not the best classifier to go with. LogisticRegression actually scores just as well, but is one of the fastest models on the list!\n",
    "\n",
    "XGBClassifier scores the highest on the testing data and also is relatively fast, only a handful of classifiers are faster. This is a strong candidate for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, scale appropriate data and use entire X as training data (does not include X_holdout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "s_X = pd.DataFrame(sscaler.fit_transform(X.iloc[:, 1:]), columns=X.columns[1:], index=X.index).join(X.iloc[:, 0]).copy()\n",
    "s_X_holdout = pd.DataFrame(sscaler.transform(X_holdout.iloc[:, 1:]), columns=X_holdout.columns[1:], index=X_holdout.index).join(X_holdout.iloc[:, 0]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mm_X = pd.DataFrame(mmscaler.fit_transform(X.iloc[:, 1:]), columns=X.columns[1:], index=X.index).join(X.iloc[:, 0]).copy()\n",
    "mm_X_holdout = pd.DataFrame(mmscaler.transform(X_holdout.iloc[:, 1:]), columns=X_holdout.columns[1:], index=X_holdout.index).join(X_holdout.iloc[:, 0]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now multiple train/test datasets, where each model performs best with certain scaled/non-scaled data. In order to test the best models from above, first we need to retrain each model using the appropriate training data, then check how the model performs on the testing data. The different scaled/non-scaled datas are listed below as well as the models they will be used with:\n",
    "- Base: X/y (train) and X_holdout/y_holdout (test); used in Naive Bayes - Bernoulli, Decision Tree and Random Forest\n",
    "- Standardized: s_X/y (train) and s_X_holdout/y_holdout (test); used in Logistic Regression, Support Vectors, Gradient Boosting, eXtreme Gradient Boosting and Extremely Randomized Trees\n",
    "- MinMaxed: mm_X/y (train) and mm_X_holdout/y_holdout (test); used in K-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_est = [i[0] for i in best_estimators]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (retrain and test with Standardized Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8907967032967034"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(only_est[0])\n",
    "only_est[0].fit(s_X, y)\n",
    "only_est[0].score(s_X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (retrain and test with MinMaxed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=-1, n_neighbors=27, p=4,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8042582417582418"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(only_est[1])\n",
    "only_est[1].fit(mm_X, y)\n",
    "only_est[1].score(mm_X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - Bernoulli (retrain and test with Base Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=3, binarize=0.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7657967032967034"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(only_est[2])\n",
    "only_est[2].fit(X, y)\n",
    "only_est[2].score(X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree (retrain and test with Base Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8914835164835165"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(only_est[3])\n",
    "only_est[3].fit(X, y)\n",
    "only_est[3].score(X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (retrain and test with Base Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=15, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=-1,\n",
      "                       oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8461538461538461"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(only_est[4])\n",
    "only_est[4].fit(X, y)\n",
    "only_est[4].score(X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vectors (retrain and test with Standardized Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.10010000000000001, break_ties=False, cache_size=200, class_weight=None,\n",
      "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8873626373626373"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(only_est[5])\n",
    "only_est[5].fit(s_X, y)\n",
    "only_est[5].score(s_X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting (retrain and test with Standardized Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='exponential', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=350,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9114010989010989"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(only_est[6])\n",
    "only_est[6].fit(s_X, y)\n",
    "only_est[6].score(s_X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eXtreme Gradient Boosting (retrain and test with Standardized Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.15000000000000002, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9052197802197802"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(only_est[7])\n",
    "only_est[7].fit(s_X, y)\n",
    "only_est[7].score(s_X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extremely Randomized Trees (retrain and test with Standardized Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=3,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8447802197802198"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(only_est[8])\n",
    "only_est[8].fit(s_X, y)\n",
    "only_est[8].score(s_X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting appears to have the greatest predictive power for the holdout!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
