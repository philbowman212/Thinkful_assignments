{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# DRILL: Third Attempt\n",
    "\n",
    "So here's your task. Get rid of as much data as possible without dropping below an average of 90% accuracy in a 10-fold cross validation.\n",
    "\n",
    "You'll want to do a few things in this process. First, dive into the data that we have and see which features are most important. This can be the raw features or the generated dummies. You may want to use PCA or correlation matrices.\n",
    "\n",
    "Can you do it without using anything related to payment amount or outstanding principal? How do you know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2019-11-16T18:02:30.451182Z",
     "start_time": "2019-11-16T18:02:27.163181Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2019-11-16T18:02:52.095561Z",
     "start_time": "2019-11-16T18:02:31.147318Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('LoanStats3d.csv', skipinitialspace=True, header=1, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Cleaning from the example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2019-11-16T18:02:52.681906Z",
     "start_time": "2019-11-16T18:02:52.095561Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[:-2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2019-11-16T18:03:33.782621Z",
     "start_time": "2019-11-16T18:03:32.494331Z"
    }
   },
   "outputs": [],
   "source": [
    "df['id'] = pd.to_numeric(df['id'], errors='coerce').copy()\n",
    "df['int_rate'] = pd.to_numeric(df['int_rate'].str.strip('%'), errors='coerce').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df.drop(['url', 'emp_title', 'zip_code', 'earliest_cr_line', 'revol_util',\n",
    "            'sub_grade', 'addr_state', 'desc'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "First do it how they did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns='loan_status')\n",
    "y = df.loan_status\n",
    "X = pd.get_dummies(X, drop_first=True).copy()\n",
    "X = X.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#cross_val_score(rfc, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "That took a long time...think twice before running the above again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's look at the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='sag', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pca = PCA(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pca.fit(X_train)\n",
    "X_tr_pca = pca.transform(X_train)\n",
    "X_te_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523006785267814\n",
      "54\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_.sum())\n",
    "print(len(pca.components_))\n",
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "So using PCA on ALL the data got the amount of components down to 54 from the 186 and still explains 95% of the variance. Let's see how this performs using Random Forest, may be useful to train/test on a k number of components and then see how performance is on the train/test models in order to tune before doing the big cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\philb\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_tr_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9699121348848254"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_te_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "for k in range(2, 103, 10):\n",
    "    print('-----Running PCA with {} components-----'.format(k))\n",
    "    pca = PCA(n_components=k)\n",
    "    print('Fitting and transforming PCA on training data...')\n",
    "    X_tr_pca = pca.fit_transform(X_train)\n",
    "    print('done...')\n",
    "    print('Transforming testing data...')\n",
    "    X_te_pca = pca.transform(X_test)\n",
    "    print('done...')\n",
    "    print('Fitting training data using random forest...')\n",
    "    rfc.fit(X_tr_pca, y_train)\n",
    "    print('done...')\n",
    "    print('assigning score...')\n",
    "    score = rfc.score(X_te_pca, y_test)\n",
    "    print('done...')\n",
    "    scores.append(score)\n",
    "    print('PCA n_components={} done... Random Forest Score: {}'.format(k, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6789204336313659,\n",
       " 0.9095334781937567,\n",
       " 0.9108277229603771,\n",
       " 0.9133924648832211,\n",
       " 0.9600446455075458,\n",
       " 0.96909248506869,\n",
       " 0.9704935940820955,\n",
       " 0.9709804200952279,\n",
       " 0.9732364430829148,\n",
       " 0.9737945119272373,\n",
       " 0.9734857929920802]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Looks like 2 components don't work well. Once the number of components is up to 12 there is almost 91% predictive power...I am curious how low we could actually go and get consistent results, but the above was very computationally expensive (random forest and PCA both take a long time to fit)! So, let's run the cross validation with PCA with 12 components (down from 186)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6684871174375336"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=12)\n",
    "X_pca = pca.fit_transform(X)\n",
    "comp_12 = cross_val_score(rfc, X_pca, y, cv=10, n_jobs=-1)\n",
    "comp_12.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Looks like the training and testing data may have just been really good for prior testing, let's see if it's better at 22 (91% above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9443001840082635"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=22)\n",
    "X_pca = pca.fit_transform(X)\n",
    "comp_22 = cross_val_score(rfc, X_pca, y, cv=10, n_jobs=-1)\n",
    "comp_22.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Looks like this does meet the average score of 90% or higher, wonder if we can do it with fewer components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9384346023393105"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=17)\n",
    "X_pca = pca.fit_transform(X)\n",
    "comp_17 = cross_val_score(rfc, X_pca, y, cv=10, n_jobs=-1)\n",
    "comp_17.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Closer...\n",
    "\n",
    "So it's somewhere between 12 and 17, let's loop this, it's going to take awhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Running cross validation for Random Forest using PCA with 13 components-----\n",
      "Fitting PCA...\n",
      "done...\n",
      "Cross validating...\n",
      "done...\n",
      "k=13 cv_mean=0.673642633299513\n",
      "-----Running cross validation for Random Forest using PCA with 14 components-----\n",
      "Fitting PCA...\n",
      "done...\n",
      "Cross validating...\n",
      "done...\n",
      "k=14 cv_mean=0.9171235149425987\n",
      "-----Running cross validation for Random Forest using PCA with 15 components-----\n",
      "Fitting PCA...\n",
      "done...\n",
      "Cross validating...\n",
      "done...\n",
      "k=15 cv_mean=0.9321248378498821\n",
      "-----Running cross validation for Random Forest using PCA with 16 components-----\n",
      "Fitting PCA...\n",
      "done...\n",
      "Cross validating...\n",
      "done...\n",
      "k=16 cv_mean=0.9362285172570581\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for k in range(13, 17, 1):\n",
    "    print('-----Running cross validation for Random Forest using PCA with {} components-----'.format(k))\n",
    "    pca = PCA(n_components=k)\n",
    "    print('Fitting PCA...')\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    print('done...')\n",
    "    print('Cross validating...')\n",
    "    cv_mean = cross_val_score(rfc, X_pca, y, cv=10, n_jobs=-1).mean()\n",
    "    print('done...')\n",
    "    scores.append(cv_mean)\n",
    "    print('k={} cv_mean={}'.format(k, cv_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Looks like there is a significant jump from PCA n_components=13 to n_components=14, now I wonder if we can get it to run faster while still maintaining accuracy above 90% while using 14 components from PCA. The next thing to tune will be the depth of the Random Forest (how many 'stories' of nodes). First, let's find out how deep it goes when unlimited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421095, 186)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421095, 14)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999304665965"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([estimator.tree_.max_depth for estimator in rfc.estimators_]).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "So, from the above we can see the max tree depth of any branch is at most 57, so let's limit this to the mean of the tree depth instead to see if we can still get good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.7"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([estimator.tree_.max_depth for estimator in rfc.estimators_]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "rfc.max_depth = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9925005046367209"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Using Random Forest with max depth of 5-----\n",
      "Cross validating...\n",
      "done...\n",
      "max_depth: 5 mean_cv: 0.921720435746149\n",
      "-----Using Random Forest with max depth of 10-----\n",
      "Cross validating...\n",
      "done...\n",
      "max_depth: 10 mean_cv: 0.9137228324801177\n",
      "-----Using Random Forest with max depth of 15-----\n",
      "Cross validating...\n",
      "done...\n",
      "max_depth: 15 mean_cv: 0.9173085766610027\n",
      "-----Using Random Forest with max depth of 20-----\n",
      "Cross validating...\n",
      "done...\n",
      "max_depth: 20 mean_cv: 0.9154327110793178\n",
      "-----Using Random Forest with max depth of 25-----\n",
      "Cross validating...\n",
      "done...\n",
      "max_depth: 25 mean_cv: 0.920509959270351\n",
      "-----Using Random Forest with max depth of 30-----\n",
      "Cross validating...\n",
      "done...\n",
      "max_depth: 30 mean_cv: 0.9180782130435556\n",
      "-----Using Random Forest with max depth of 35-----\n",
      "Cross validating...\n",
      "done...\n",
      "max_depth: 35 mean_cv: 0.9203152505237393\n",
      "-----Using Random Forest with max depth of 40-----\n",
      "Cross validating...\n",
      "done...\n",
      "max_depth: 40 mean_cv: 0.9137489346851522\n",
      "-----Using Random Forest with max depth of 45-----\n",
      "Cross validating...\n",
      "done...\n",
      "max_depth: 45 mean_cv: 0.9185247135771135\n",
      "-----Using Random Forest with max depth of 50-----\n",
      "Cross validating...\n",
      "done...\n",
      "max_depth: 50 mean_cv: 0.9186172195373243\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "means = []\n",
    "for k in range(5, 51, 5):\n",
    "    rfc = RandomForestClassifier(n_estimators=10, max_depth=k)\n",
    "    print('-----Using Random Forest with max depth of {}-----'.format(k))\n",
    "    print('Cross validating...')\n",
    "    score = cross_val_score(rfc, X_pca, y, cv=10, n_jobs=-1)\n",
    "    print('done...')\n",
    "    scores.append(score)\n",
    "    mean = score.mean()\n",
    "    means.append(mean)\n",
    "    print('max_depth: {} mean_cv: {}'.format(k, mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Surprisingly, the model with the max depth of 5 seems to be the most general and also the most consistent. It also keeps a prediction rate over 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=14, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "rfc.max_depth=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "rfc.n_jobs=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87884401, 0.9361687 , 0.9427228 , 0.91375175, 0.9151033 ,\n",
       "       0.9315127 , 0.90595835, 0.8991427 , 0.91200988, 0.91485774])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, X_pca, y, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_pca, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "So, the above is the final model. PCA was used to reduce dimensions down from 186 to 14, then Random Forest Classifier was used to model the data. There are some concerns about the variability between cross validation instances, but this was the most consistent and also most general of the Random Forest Classifiers, so this would be the ultimate model I would use moving forward. Let's do one more instantiation with the model and use cross validation to observe if we have consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, max_depth=5, n_jobs=-1)\n",
    "pca = PCA(n_components=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                        max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                        oob_score=False, random_state=None, verbose=0,\n",
       "                        warm_start=False),\n",
       " PCA(copy=True, iterated_power='auto', n_components=14, random_state=None,\n",
       "     svd_solver='auto', tol=0.0, whiten=False))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.88668044, 0.94443257, 0.93472014, 0.93678611, 0.9337687 ,\n",
       "        0.93545476, 0.93120236, 0.93113111, 0.8715178 , 0.92511756]),\n",
       " 0.9230811558723373)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca = pca.fit_transform(X)\n",
    "final_scores = cross_val_score(rfc, X_pca, y, cv=10, n_jobs=-1)\n",
    "final_scores, final_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.31% accuracy over 10-fold Cross Validation\n"
     ]
    }
   ],
   "source": [
    "print(f'{round(final_scores.mean()*100, 2)}% accuracy over 10-fold Cross Validation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
