{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "In this assignment, you'll be working with the [U.S. Education Dataset](https://www.kaggle.com/noriuk/us-education-datasets-unification-project/home) from Kaggle. The data gives detailed state level information on several facets of the state of education on an annual basis. To learn more about the data and the column descriptions, click the Kaggle link above. \n",
    "\n",
    "Access this data from the Thinkful database using the following credentials:\n",
    "\n",
    "postgres_user = 'dsbc_student'<br>\n",
    "postgres_pw = '7\\*.8G9QH21'<br>\n",
    "postgres_host = '142.93.121.174'<br>\n",
    "postgres_port = '5432'<br>\n",
    "postgres_db = 'useducation'<br>\n",
    "\n",
    "To complete this assignment, submit a link to a Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "1. Determine all the variable types and find the fraction of the missing values for each variable.\n",
    "2. Notice that the data has a time dimension (year). For this assignment, forget about time and treat all the observations as if they're from the same year. Choose a strategy to deal with the missing values for each variables. For which variables would filling in the missing values with some value make sense? For which might tossing out the records entirely make sense?\n",
    "3. Now, take into account the time factor. Replicate your second answer but this time fill in the missing values by using a statistic that is calculated within the year of the observation. For example, if you want to fill a missing value for a variable with the mean of that variable, calculate the mean by using *only* the observations for that specific year.\n",
    "4. This time, fill in the missing values using interpolation (extrapolation).\n",
    "5. Compare your results for the 2nd, 3rd, and 4th questions. Do you find any meaningful differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'useducation'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "                        postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "df = pd.read_sql_query('select * from useducation', con=engine)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Determine all the variable types and find the fraction of the missing values for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1492 entries, 0 to 1491\n",
      "Data columns (total 25 columns):\n",
      "PRIMARY_KEY                     1492 non-null object\n",
      "STATE                           1492 non-null object\n",
      "YEAR                            1492 non-null int64\n",
      "ENROLL                          1229 non-null float64\n",
      "TOTAL_REVENUE                   1280 non-null float64\n",
      "FEDERAL_REVENUE                 1280 non-null float64\n",
      "STATE_REVENUE                   1280 non-null float64\n",
      "LOCAL_REVENUE                   1280 non-null float64\n",
      "TOTAL_EXPENDITURE               1280 non-null float64\n",
      "INSTRUCTION_EXPENDITURE         1280 non-null float64\n",
      "SUPPORT_SERVICES_EXPENDITURE    1280 non-null float64\n",
      "OTHER_EXPENDITURE               1229 non-null float64\n",
      "CAPITAL_OUTLAY_EXPENDITURE      1280 non-null float64\n",
      "GRADES_PK_G                     1319 non-null float64\n",
      "GRADES_KG_G                     1360 non-null float64\n",
      "GRADES_4_G                      1361 non-null float64\n",
      "GRADES_8_G                      1361 non-null float64\n",
      "GRADES_12_G                     1361 non-null float64\n",
      "GRADES_1_8_G                    1361 non-null float64\n",
      "GRADES_9_12_G                   1361 non-null float64\n",
      "GRADES_ALL_G                    1319 non-null float64\n",
      "AVG_MATH_4_SCORE                536 non-null float64\n",
      "AVG_MATH_8_SCORE                532 non-null float64\n",
      "AVG_READING_4_SCORE             533 non-null float64\n",
      "AVG_READING_8_SCORE             498 non-null float64\n",
      "dtypes: float64(22), int64(1), object(2)\n",
      "memory usage: 279.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57948.0</td>\n",
       "      <td>58025.0</td>\n",
       "      <td>41167.0</td>\n",
       "      <td>471564.0</td>\n",
       "      <td>196386.0</td>\n",
       "      <td>676174.0</td>\n",
       "      <td>208.327876</td>\n",
       "      <td>252.187522</td>\n",
       "      <td>207.963517</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>6714.0</td>\n",
       "      <td>79117.0</td>\n",
       "      <td>30847.0</td>\n",
       "      <td>112335.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.859712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55433.0</td>\n",
       "      <td>49081.0</td>\n",
       "      <td>37410.0</td>\n",
       "      <td>437127.0</td>\n",
       "      <td>175210.0</td>\n",
       "      <td>614881.0</td>\n",
       "      <td>215.253932</td>\n",
       "      <td>265.366278</td>\n",
       "      <td>206.212716</td>\n",
       "      <td>262.169895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34632.0</td>\n",
       "      <td>36011.0</td>\n",
       "      <td>27651.0</td>\n",
       "      <td>281338.0</td>\n",
       "      <td>123113.0</td>\n",
       "      <td>405259.0</td>\n",
       "      <td>210.206028</td>\n",
       "      <td>256.312090</td>\n",
       "      <td>208.634458</td>\n",
       "      <td>264.619665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>418418.0</td>\n",
       "      <td>363296.0</td>\n",
       "      <td>270675.0</td>\n",
       "      <td>3286034.0</td>\n",
       "      <td>1372011.0</td>\n",
       "      <td>4717112.0</td>\n",
       "      <td>208.398961</td>\n",
       "      <td>260.892247</td>\n",
       "      <td>196.764414</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     NaN      2678885.0         304177.0   \n",
       "1      1992_ALASKA      ALASKA  1992     NaN      1049591.0         106780.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992     NaN      3258079.0         297888.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     NaN      1711959.0         178571.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     NaN     26260025.0        2072470.0   \n",
       "\n",
       "   STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0      1659028.0       715680.0          2653798.0                1481703.0   \n",
       "1       720711.0       222100.0           972488.0                 498362.0   \n",
       "2      1369815.0      1590376.0          3401580.0                1435908.0   \n",
       "3       958785.0       574603.0          1743022.0                 964323.0   \n",
       "4     16546514.0      7641041.0         27138832.0               14358922.0   \n",
       "\n",
       "   ...  GRADES_4_G  GRADES_8_G  GRADES_12_G  GRADES_1_8_G  GRADES_9_12_G  \\\n",
       "0  ...     57948.0     58025.0      41167.0      471564.0       196386.0   \n",
       "1  ...      9748.0      8789.0       6714.0       79117.0        30847.0   \n",
       "2  ...     55433.0     49081.0      37410.0      437127.0       175210.0   \n",
       "3  ...     34632.0     36011.0      27651.0      281338.0       123113.0   \n",
       "4  ...    418418.0    363296.0     270675.0     3286034.0      1372011.0   \n",
       "\n",
       "   GRADES_ALL_G  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  AVG_READING_4_SCORE  \\\n",
       "0      676174.0        208.327876        252.187522           207.963517   \n",
       "1      112335.0               NaN               NaN                  NaN   \n",
       "2      614881.0        215.253932        265.366278           206.212716   \n",
       "3      405259.0        210.206028        256.312090           208.634458   \n",
       "4     4717112.0        208.398961        260.892247           196.764414   \n",
       "\n",
       "   AVG_READING_8_SCORE  \n",
       "0                  NaN  \n",
       "1           258.859712  \n",
       "2           262.169895  \n",
       "3           264.619665  \n",
       "4                  NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                     1487\n",
       "STATE                             80\n",
       "YEAR                              26\n",
       "ENROLL                          1224\n",
       "TOTAL_REVENUE                   1274\n",
       "FEDERAL_REVENUE                 1275\n",
       "STATE_REVENUE                   1251\n",
       "LOCAL_REVENUE                   1275\n",
       "TOTAL_EXPENDITURE               1275\n",
       "INSTRUCTION_EXPENDITURE         1275\n",
       "SUPPORT_SERVICES_EXPENDITURE    1275\n",
       "OTHER_EXPENDITURE               1222\n",
       "CAPITAL_OUTLAY_EXPENDITURE      1275\n",
       "GRADES_PK_G                     1261\n",
       "GRADES_KG_G                     1348\n",
       "GRADES_4_G                      1340\n",
       "GRADES_8_G                      1347\n",
       "GRADES_12_G                     1342\n",
       "GRADES_1_8_G                    1360\n",
       "GRADES_9_12_G                   1358\n",
       "GRADES_ALL_G                    1318\n",
       "AVG_MATH_4_SCORE                 535\n",
       "AVG_MATH_8_SCORE                 531\n",
       "AVG_READING_4_SCORE              532\n",
       "AVG_READING_8_SCORE              497\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Types - Nominal (N), Ordinal (O), Interval (I), Ratio (R)\n",
    "- PRIMARY_KEY - N\n",
    "- STATE - N\n",
    "- YEAR - O/I\n",
    "- ENROLL - R\n",
    "- TOTAL_REVENUE - R\n",
    "- FEDERAL_REVENUE - R\n",
    "- STATE_REVENUE - R\n",
    "- LOCAL_REVENUE - R\n",
    "- TOTAL_EXPENDITURE - R\n",
    "- INSTRUCTION_EXPENDITURE - R\n",
    "- SUPPORT_SERVICES_EXPENDITURE - R\n",
    "- OTHER_EXPENDITURE - R\n",
    "- CAPITAL_OUTLAY_EXPENDITURE - R\n",
    "- GRADES_PK_G - R\n",
    "- GRADES_KG_G - R\n",
    "- GRADES_4_G - R\n",
    "- GRADES_8_G - R\n",
    "- GRADES_12_G - R\n",
    "- GRADES_1_8_G - R\n",
    "- GRADES_9_12_G - R\n",
    "- GRADES_ALL_G - R\n",
    "- AVG_MATH_4_SCORE - R\n",
    "- AVG_MATH_8_SCORE - R\n",
    "- AVG_READING_4_SCORE - R\n",
    "- AVG_READING_8_SCORE - R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fraction of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                      0.000000\n",
       "STATE                            0.000000\n",
       "YEAR                             0.000000\n",
       "ENROLL                          17.627346\n",
       "TOTAL_REVENUE                   14.209115\n",
       "FEDERAL_REVENUE                 14.209115\n",
       "STATE_REVENUE                   14.209115\n",
       "LOCAL_REVENUE                   14.209115\n",
       "TOTAL_EXPENDITURE               14.209115\n",
       "INSTRUCTION_EXPENDITURE         14.209115\n",
       "SUPPORT_SERVICES_EXPENDITURE    14.209115\n",
       "OTHER_EXPENDITURE               17.627346\n",
       "CAPITAL_OUTLAY_EXPENDITURE      14.209115\n",
       "GRADES_PK_G                     11.595174\n",
       "GRADES_KG_G                      8.847185\n",
       "GRADES_4_G                       8.780161\n",
       "GRADES_8_G                       8.780161\n",
       "GRADES_12_G                      8.780161\n",
       "GRADES_1_8_G                     8.780161\n",
       "GRADES_9_12_G                    8.780161\n",
       "GRADES_ALL_G                    11.595174\n",
       "AVG_MATH_4_SCORE                64.075067\n",
       "AVG_MATH_8_SCORE                64.343164\n",
       "AVG_READING_4_SCORE             64.276139\n",
       "AVG_READING_8_SCORE             66.621984\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()*100/df.isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Notice that the data has a time dimension (year). For this assignment, forget about time and treat all the observations as if they're from the same year. Choose a strategy to deal with the missing values for each variables. For which variables would filling in the missing values with some value make sense? For which might tossing out the records entirely make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the average score variables are primarily null - all of them with a greater than 64% null amount - if we were looking at the data as if it were a single year, it would likely be of no use to use this variable and we're probably better off getting rid of this variable altogether, but not necessarily the rows themselves. However, it ultimately depends on the overall goal we wish to achieve from this data. If we are curious at the connection between revenue/expenditure and average scores, then we would probably only want to use the data that is complete for both average score and our other variables of interest. For all other variables (namely enrollment/revenue/expenditure data) it may be better to impute the null values, or better yet interpolate them with values that make the most sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_year_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_year_df.drop(columns=['PRIMARY_KEY','YEAR', 'AVG_MATH_4_SCORE',\n",
    "                           'AVG_MATH_8_SCORE', 'AVG_READING_4_SCORE',\n",
    "                           'AVG_READING_8_SCORE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_filled_df = same_year_df.fillna(same_year_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1492 entries, 0 to 1491\n",
      "Data columns (total 19 columns):\n",
      "STATE                           1492 non-null object\n",
      "ENROLL                          1492 non-null float64\n",
      "TOTAL_REVENUE                   1492 non-null float64\n",
      "FEDERAL_REVENUE                 1492 non-null float64\n",
      "STATE_REVENUE                   1492 non-null float64\n",
      "LOCAL_REVENUE                   1492 non-null float64\n",
      "TOTAL_EXPENDITURE               1492 non-null float64\n",
      "INSTRUCTION_EXPENDITURE         1492 non-null float64\n",
      "SUPPORT_SERVICES_EXPENDITURE    1492 non-null float64\n",
      "OTHER_EXPENDITURE               1492 non-null float64\n",
      "CAPITAL_OUTLAY_EXPENDITURE      1492 non-null float64\n",
      "GRADES_PK_G                     1492 non-null float64\n",
      "GRADES_KG_G                     1492 non-null float64\n",
      "GRADES_4_G                      1492 non-null float64\n",
      "GRADES_8_G                      1492 non-null float64\n",
      "GRADES_12_G                     1492 non-null float64\n",
      "GRADES_1_8_G                    1492 non-null float64\n",
      "GRADES_9_12_G                   1492 non-null float64\n",
      "GRADES_ALL_G                    1492 non-null float64\n",
      "dtypes: float64(18), object(1)\n",
      "memory usage: 215.7+ KB\n"
     ]
    }
   ],
   "source": [
    "mean_filled_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE                           0.0\n",
       "ENROLL                          0.0\n",
       "TOTAL_REVENUE                   0.0\n",
       "FEDERAL_REVENUE                 0.0\n",
       "STATE_REVENUE                   0.0\n",
       "LOCAL_REVENUE                   0.0\n",
       "TOTAL_EXPENDITURE               0.0\n",
       "INSTRUCTION_EXPENDITURE         0.0\n",
       "SUPPORT_SERVICES_EXPENDITURE    0.0\n",
       "OTHER_EXPENDITURE               0.0\n",
       "CAPITAL_OUTLAY_EXPENDITURE      0.0\n",
       "GRADES_PK_G                     0.0\n",
       "GRADES_KG_G                     0.0\n",
       "GRADES_4_G                      0.0\n",
       "GRADES_8_G                      0.0\n",
       "GRADES_12_G                     0.0\n",
       "GRADES_1_8_G                    0.0\n",
       "GRADES_9_12_G                   0.0\n",
       "GRADES_ALL_G                    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_filled_df.isnull().sum()*100/mean_filled_df.isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Now, take into account the time factor. Replicate your second answer but this time fill in the missing values by using a statistic that is calculated within the year of the observation. For example, if you want to fill a missing value for a variable with the mean of that variable, calculate the mean by using only the observations for that specific year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year_mean_filled = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(by_year_mean_filled.columns)[3:]:\n",
    "    by_year_mean_filled[col] = by_year_mean_filled.groupby(['YEAR'])[col].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1492 entries, 0 to 1491\n",
      "Data columns (total 25 columns):\n",
      "PRIMARY_KEY                     1492 non-null object\n",
      "STATE                           1492 non-null object\n",
      "YEAR                            1492 non-null int64\n",
      "ENROLL                          1385 non-null float64\n",
      "TOTAL_REVENUE                   1441 non-null float64\n",
      "FEDERAL_REVENUE                 1441 non-null float64\n",
      "STATE_REVENUE                   1441 non-null float64\n",
      "LOCAL_REVENUE                   1441 non-null float64\n",
      "TOTAL_EXPENDITURE               1441 non-null float64\n",
      "INSTRUCTION_EXPENDITURE         1441 non-null float64\n",
      "SUPPORT_SERVICES_EXPENDITURE    1441 non-null float64\n",
      "OTHER_EXPENDITURE               1385 non-null float64\n",
      "CAPITAL_OUTLAY_EXPENDITURE      1441 non-null float64\n",
      "GRADES_PK_G                     1390 non-null float64\n",
      "GRADES_KG_G                     1390 non-null float64\n",
      "GRADES_4_G                      1390 non-null float64\n",
      "GRADES_8_G                      1390 non-null float64\n",
      "GRADES_12_G                     1390 non-null float64\n",
      "GRADES_1_8_G                    1390 non-null float64\n",
      "GRADES_9_12_G                   1390 non-null float64\n",
      "GRADES_ALL_G                    1390 non-null float64\n",
      "AVG_MATH_4_SCORE                632 non-null float64\n",
      "AVG_MATH_8_SCORE                632 non-null float64\n",
      "AVG_READING_4_SCORE             632 non-null float64\n",
      "AVG_READING_8_SCORE             632 non-null float64\n",
      "dtypes: float64(22), int64(1), object(2)\n",
      "memory usage: 279.8+ KB\n"
     ]
    }
   ],
   "source": [
    "by_year_mean_filled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                      0.000000\n",
       "STATE                            0.000000\n",
       "YEAR                             0.000000\n",
       "ENROLL                           7.171582\n",
       "TOTAL_REVENUE                    3.418231\n",
       "FEDERAL_REVENUE                  3.418231\n",
       "STATE_REVENUE                    3.418231\n",
       "LOCAL_REVENUE                    3.418231\n",
       "TOTAL_EXPENDITURE                3.418231\n",
       "INSTRUCTION_EXPENDITURE          3.418231\n",
       "SUPPORT_SERVICES_EXPENDITURE     3.418231\n",
       "OTHER_EXPENDITURE                7.171582\n",
       "CAPITAL_OUTLAY_EXPENDITURE       3.418231\n",
       "GRADES_PK_G                      6.836461\n",
       "GRADES_KG_G                      6.836461\n",
       "GRADES_4_G                       6.836461\n",
       "GRADES_8_G                       6.836461\n",
       "GRADES_12_G                      6.836461\n",
       "GRADES_1_8_G                     6.836461\n",
       "GRADES_9_12_G                    6.836461\n",
       "GRADES_ALL_G                     6.836461\n",
       "AVG_MATH_4_SCORE                57.640751\n",
       "AVG_MATH_8_SCORE                57.640751\n",
       "AVG_READING_4_SCORE             57.640751\n",
       "AVG_READING_8_SCORE             57.640751\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_year_mean_filled.isnull().sum()*100/by_year_mean_filled.isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. This time, fill in the missing values using interpolation (extrapolation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_interpolate_df = df.interpolate(limit_direction='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1492 entries, 0 to 1491\n",
      "Data columns (total 25 columns):\n",
      "PRIMARY_KEY                     1492 non-null object\n",
      "STATE                           1492 non-null object\n",
      "YEAR                            1492 non-null int64\n",
      "ENROLL                          1492 non-null float64\n",
      "TOTAL_REVENUE                   1492 non-null float64\n",
      "FEDERAL_REVENUE                 1492 non-null float64\n",
      "STATE_REVENUE                   1492 non-null float64\n",
      "LOCAL_REVENUE                   1492 non-null float64\n",
      "TOTAL_EXPENDITURE               1492 non-null float64\n",
      "INSTRUCTION_EXPENDITURE         1492 non-null float64\n",
      "SUPPORT_SERVICES_EXPENDITURE    1492 non-null float64\n",
      "OTHER_EXPENDITURE               1492 non-null float64\n",
      "CAPITAL_OUTLAY_EXPENDITURE      1492 non-null float64\n",
      "GRADES_PK_G                     1492 non-null float64\n",
      "GRADES_KG_G                     1492 non-null float64\n",
      "GRADES_4_G                      1492 non-null float64\n",
      "GRADES_8_G                      1492 non-null float64\n",
      "GRADES_12_G                     1492 non-null float64\n",
      "GRADES_1_8_G                    1492 non-null float64\n",
      "GRADES_9_12_G                   1492 non-null float64\n",
      "GRADES_ALL_G                    1492 non-null float64\n",
      "AVG_MATH_4_SCORE                1492 non-null float64\n",
      "AVG_MATH_8_SCORE                1492 non-null float64\n",
      "AVG_READING_4_SCORE             1492 non-null float64\n",
      "AVG_READING_8_SCORE             1492 non-null float64\n",
      "dtypes: float64(22), int64(1), object(2)\n",
      "memory usage: 279.8+ KB\n"
     ]
    }
   ],
   "source": [
    "linear_interpolate_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                     0.0\n",
       "STATE                           0.0\n",
       "YEAR                            0.0\n",
       "ENROLL                          0.0\n",
       "TOTAL_REVENUE                   0.0\n",
       "FEDERAL_REVENUE                 0.0\n",
       "STATE_REVENUE                   0.0\n",
       "LOCAL_REVENUE                   0.0\n",
       "TOTAL_EXPENDITURE               0.0\n",
       "INSTRUCTION_EXPENDITURE         0.0\n",
       "SUPPORT_SERVICES_EXPENDITURE    0.0\n",
       "OTHER_EXPENDITURE               0.0\n",
       "CAPITAL_OUTLAY_EXPENDITURE      0.0\n",
       "GRADES_PK_G                     0.0\n",
       "GRADES_KG_G                     0.0\n",
       "GRADES_4_G                      0.0\n",
       "GRADES_8_G                      0.0\n",
       "GRADES_12_G                     0.0\n",
       "GRADES_1_8_G                    0.0\n",
       "GRADES_9_12_G                   0.0\n",
       "GRADES_ALL_G                    0.0\n",
       "AVG_MATH_4_SCORE                0.0\n",
       "AVG_MATH_8_SCORE                0.0\n",
       "AVG_READING_4_SCORE             0.0\n",
       "AVG_READING_8_SCORE             0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_interpolate_df.isnull().sum()*100/linear_interpolate_df.isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Compare your results for the 2nd, 3rd, and 4th questions. Do you find any meaningful differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are large differences between all three methods above. \n",
    "\n",
    "Regarding the first method, where I simply imputed the mean over all the years into the null values it is useful because it eliminates all null values. The drawback of this method is likely the accuracy of that imputation. It is very unlikely that filling the nulls with the overall mean is very helpful - unless perhaps as the question suggests all the data is from a singular year. But we know this is not the case - therefore this is likely not a good method for cleaning this data.\n",
    "\n",
    "As for the second method - there is an improvement. Now the mean for that given year is imputed to the null values rather than an overall mean - likely making the estimates from imputation more accurate than before. However, when doing it this way we still end up with a relatively large number of null values (since for some years some features were completely null, thus imputing a null value over a null value).\n",
    "\n",
    "For the final method, linear interpolation was used. Of all three, this method is likely the best as it attempts to fill in empty values based on linear relationships of the data. However, this is not a perfect method. What if the relationship is not linear? Perhaps another interpolation method should be used for certain features. Also should this be used on features where the majority of values are null (AVG_SCORE columns)?\n",
    "\n",
    "Ultimately the question ends up being, 'when should I interpolate and when should I impute!?'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
