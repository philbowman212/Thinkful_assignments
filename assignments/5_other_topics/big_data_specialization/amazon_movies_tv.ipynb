{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "amazon_movies_tv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGcXZdr4F4qf",
        "colab_type": "text"
      },
      "source": [
        "# Challenge: sentiment analysis for Amazon reviews\n",
        "Now that you've looked at an example of how we can use Spark in batch mode, it's time to try it out on your own.\n",
        "\n",
        "In this challenge you'll work on a sentiment analysis dataset: the [Amazon reviews dataset](http://jmcauley.ucsd.edu/data/amazon/). You should choose one of the 5-core datasets. Keep in mind that if the data is g-zipped, you'll need to unpack the dataset before you use it.\n",
        "\n",
        "You should complete this challenge in a Jupyter notebook, which you'll need to work on Colab.\n",
        "\n",
        "Now, on to the task at hand!\n",
        "\n",
        "It's always important to start with a clear goal in mind. In this case, we'd like to **determine if we can predict whether a review is positive or negative based on the language in the review.**\n",
        "\n",
        "We're going to tackle this problem with Spark, so you'll need to apply the principles you've learned thus far in the context of Spark.\n",
        "\n",
        "Some tips to help you get started:\n",
        "\n",
        "- Don't forget to install Java, Spark, Findspark and PySpark. You may also need to re-mount your drive to Colab. You can use the codes from the previous assignment for this purpose.\n",
        "- Pyspark always needs to point at a running Spark instance. You can do that using a **SparkContext**.\n",
        "- We're working in batch mode, so you'll need to load an entire file into memory in order to run any models you build.\n",
        "- Spark likes to execute models in a pipeline, so remember that when the time comes to set up your model.\n",
        "- Spark's machine learning algorithms expect numeric variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNzllBQgKXQe",
        "colab_type": "text"
      },
      "source": [
        "# Spark Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaujwz5bLGJW",
        "colab_type": "text"
      },
      "source": [
        "Install Spark and Java."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5JUcuZkGXel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL2HNayiLOh0",
        "colab_type": "text"
      },
      "source": [
        "Install findspark and pyspark packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKt6xCX_Kjzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q findspark\n",
        "!pip install -q pyspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3LNeCTzLTV5",
        "colab_type": "text"
      },
      "source": [
        "Set path variables for Java and Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFiBbqKUKkWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUUfoykELBHm",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0xebViIKppx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c461f925-6905-468b-f273-06be61b2c505"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hnn97YBpy8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "4594d08d-a9ce-4ff8-8ce7-288b48155fbc"
      },
      "source": [
        "!sudo update-alternatives --config java"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 2 choices for the alternative java (providing /usr/bin/java).\n",
            "\n",
            "  Selection    Path                                            Priority   Status\n",
            "------------------------------------------------------------\n",
            "  0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode\n",
            "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode\n",
            "* 2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvqb4t2jLimP",
        "colab_type": "text"
      },
      "source": [
        "Spark imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca-xPoWIKrRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import isnan, when, count, col, udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST92mF05MnHu",
        "colab_type": "text"
      },
      "source": [
        "Set up specific names and locations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE4slWCOLvr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = \"/content/gdrive/My Drive/thinkful_big_data/Colab Datasets/Movies_and_TV_5.json\"\n",
        "APP_NAME = \"Amazon Movies and TV Reviews Sentiment Analysis\"\n",
        "SPARK_URL = \"local[*]\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJBBzp2hMsBN",
        "colab_type": "text"
      },
      "source": [
        "Create spark session and create dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR_8KcQ5MQFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
        "df = spark.read.options(inferschema = \"true\").json(DATA_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0WM2TL9SNWl",
        "colab_type": "text"
      },
      "source": [
        "Make sure it's up and running."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vAjgzApSKbd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "d9bb1436-4f30-4225-d754-345366c61cdf"
      },
      "source": [
        "spark.sparkContext"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://19df67fca366:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Amazon Movies and TV Reviews Sentiment Analysis</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=Amazon Movies and TV Reviews Sentiment Analysis>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtV6BBW8NcqS",
        "colab_type": "text"
      },
      "source": [
        "Take a quick look at how the data looks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJrL9X55MjRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "50b561d1-17e8-4dfe-9539-71742bd9c231"
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "|0005019281| [0, 0]|    4.0|This is a charmin...|02 26, 2008| ADZPIG9QOCDG5|Alice L. Larson \"...|good version of a...|    1203984000|\n",
            "|0005019281| [0, 0]|    3.0|It was good but n...|12 30, 2013|A35947ZP82G7JH|       Amarah Strack|Good but not as m...|    1388361600|\n",
            "|0005019281| [0, 0]|    3.0|Don't get me wron...|12 30, 2013|A3UORV8A9D5L2E|     Amazon Customer|Winkler's Perform...|    1388361600|\n",
            "|0005019281| [0, 0]|    5.0|Henry Winkler is ...|02 13, 2008|A1VKW06X1O2X7V|Amazon Customer \"...|It's an enjoyable...|    1202860800|\n",
            "|0005019281| [0, 0]|    4.0|This is one of th...|12 22, 2013|A3R27T4HADWFFJ|                BABE|    Best Scrooge yet|    1387670400|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1MBGMJtfZzw",
        "colab_type": "text"
      },
      "source": [
        "Limit DataFrame to just the \"two variables\" of interest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVMiilg9fhBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.select('overall', 'reviewText')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3JQkEfjNntc",
        "colab_type": "text"
      },
      "source": [
        "Looks like in order to perform sentiment analysis a cutoff of positive and negative is going to have to be made regarding the overall score. I'm going to make that cutoff at 3. Any reviews with a score less than 3 are negative (so reviews at 1 or 2). And any reviews over 3 will be regarded as positive (4 and 5). Reviews of 3 are going to be considered neutral and therefore won't help with the analysis of positive or negative sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNCsFmw-SD2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f696fa90-35ac-4a1a-f116-2f644133113b"
      },
      "source": [
        "df.groupby('overall').count().show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|overall| count|\n",
            "+-------+------+\n",
            "|    1.0|104219|\n",
            "|    4.0|382994|\n",
            "|    3.0|201302|\n",
            "|    2.0|102410|\n",
            "|    5.0|906608|\n",
            "+-------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8UNoXhDTgLl",
        "colab_type": "text"
      },
      "source": [
        "It is plain to see that the number of positive reviews far outweigh the number of negative reviews. Depending on the corpus/dataset use case, this could be an important or unimportant thing to the model as the class imbalance could add a general bias toward choosing a positive score on the basis that it simply occurs more in the training set. For this particular model I am going to assume that the class imbalance is an accurate depiction of the distribution out in the wild (people will generally rate movies/TV shows at a higher rating on average), therefore nothing will be done to deal with this imbalance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGAbkG8ETGeY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1be5b9b0-5514-4ed6-857f-4453a619bb17"
      },
      "source": [
        "df.select('overall').agg({'overall': 'mean'}).show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|     avg(overall)|\n",
            "+-----------------+\n",
            "|4.110648217148062|\n",
            "+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjJipfhlbLPj",
        "colab_type": "text"
      },
      "source": [
        "Goes to show that reviews are very much on the positive end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65fMB9Rjb5_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36df3ebb-c499-4091-e881-a475ccd27ba8"
      },
      "source": [
        "df.select('overall').na.drop().count(), df.count()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1697533, 1697533)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN1_Fid-duxu",
        "colab_type": "text"
      },
      "source": [
        "We can see that none of the reviews are missing the value for the review score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8ZeIToqdoLk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca7a5f29-cccc-47a9-a1c0-d635eb915f69"
      },
      "source": [
        "df.select('reviewText').na.drop().count(), df.count()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1697533, 1697533)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rFdUwJSd-ES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "dae5da29-0190-40bc-9cc5-343078031e07"
      },
      "source": [
        "df.select('overall', 'reviewText').summary().show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+--------------------+\n",
            "|summary|           overall|          reviewText|\n",
            "+-------+------------------+--------------------+\n",
            "|  count|           1697533|             1697533|\n",
            "|   mean| 4.110648217148062|                null|\n",
            "| stddev|1.1976147523955183|                null|\n",
            "|    min|               1.0|                    |\n",
            "|    25%|               4.0|                null|\n",
            "|    50%|               5.0|                null|\n",
            "|    75%|               5.0|                null|\n",
            "|    max|               5.0|~~~~~Prom Night 3...|\n",
            "+-------+------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0wzjOC5u7Dn",
        "colab_type": "text"
      },
      "source": [
        "Filter out all scores equal to 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cERS-vxum7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.filter(df.overall != 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0WrlGnWurx0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "dd045401-7283-4468-8319-559f2bbbdb95"
      },
      "source": [
        "df.agg({'overall': 'mean'}).show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|     avg(overall)|\n",
            "+-----------------+\n",
            "|4.260074146304949|\n",
            "+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmMa8QH3vAT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0228c476-4d53-444d-832e-b6505f6fb23e"
      },
      "source": [
        "df.select('overall').distinct().show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+\n",
            "|overall|\n",
            "+-------+\n",
            "|    1.0|\n",
            "|    4.0|\n",
            "|    2.0|\n",
            "|    5.0|\n",
            "+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcZHcxU6vl5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "udfRemap = udf(f=lambda x: 1 if x > 3 else 0, returnType=IntegerType())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BETMPz2Xx6wA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.withColumn('overall', udfRemap('overall'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m58BWW47yzgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ab2bf454-9342-40bf-ee9c-0d12f342e16a"
      },
      "source": [
        "df.groupby('overall').count().show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+\n",
            "|overall|  count|\n",
            "+-------+-------+\n",
            "|      1|1289602|\n",
            "|      0| 206629|\n",
            "+-------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFEONU9zzHCR",
        "colab_type": "text"
      },
      "source": [
        "This reiterates how much of a class imbalance there is between positive and negative reviews. But even so there is a lot of data here that we can deal with and we'll go ahead and try and see if we can get this in the right format to start running models on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xoIT2EyzAc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainSet, testSet) = df.randomSplit([.8, .2], seed=2345)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGEg4-Gizsa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(inputCol='reviewText', outputCol='words')\n",
        "hashtf = HashingTF(inputCol='words', outputCol='tf')\n",
        "idf = IDF(inputCol='tf', outputCol='features', minDocFreq=5)\n",
        "label_stringIdx = StringIndexer(inputCol='overall', outputCol='label')\n",
        "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])\n",
        "pipelineFit = pipeline.fit(trainSet)\n",
        "train_df = pipelineFit.transform(trainSet)\n",
        "test_df = pipelineFit.transform(testSet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q6AUJ1x26qP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1f4b98d-f1d6-4670-984e-257cfa5a3f37"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(maxIter=100)\n",
        "lrModel = lr.fit(train_df)\n",
        "predictions = lrModel.transform(test_df)\n",
        "\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8251046842815946"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt1ci6hUFOh4",
        "colab_type": "text"
      },
      "source": [
        "This is the AUC which isn't a bad measure by any means as it gives a good overall look at the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwdSTMpI3nPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f5bb2a9-d2a7-4a54-db43-0e9b2b0c2085"
      },
      "source": [
        "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(testSet.count())\n",
        "accuracy"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8745700229321103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f-NHaCeB41_",
        "colab_type": "text"
      },
      "source": [
        "And there we have it, using simple logistic regression and the power of big data, the model was able to accurately classify 87% of the reviews. My guess is that it's better at classfiying the positives than the negatives. Note, the negative reviews got switched to positive, so now a 1 indicates the occurrence of a negative review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtIf0MDPCXA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3279b5ae-e265-418f-d0b8-f8fd5c904e01"
      },
      "source": [
        "predictions.filter((predictions.label == 1) & (predictions.label == predictions.prediction)).count() / predictions.filter(predictions.label == 1).count()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6142156391266712"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kawt8z0EFOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f92e6eba-b729-417f-8b07-1c1c08df906c"
      },
      "source": [
        "predictions.filter((predictions.label == 0) & (predictions.label == predictions.prediction)).count() / predictions.filter(predictions.label == 0).count()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9164680297800548"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFFFfJbNE-rB",
        "colab_type": "text"
      },
      "source": [
        "So as expected, the model is pretty good at identifing a positive review correctly at 92%, but it isn't nearly as good at identifying a negative review with only 61% accuracy. There are numerous ways this could be improved. For one thing there was absolutely no text cleaning done, this is essentially performing on the raw text (which is quite impressive!), so obviously some cleaning could help. Also, to deal with the class imbalance, it could be a good idea to try out SMOTE or some resampling technique (over sample negatives, under sample positives) to get a more even occurrence of each class. But for a first model in Spark, I'll take this as a win!"
      ]
    }
  ]
}